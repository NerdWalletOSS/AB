
\section{Introduction\label{sec:Intro}}

In a binary experiment, each trial has only two possible outcomes, a success(1) or failure(0).

A population being experimented on has an intrinsic property $\theta$ which is the likelihood 
that they perform the trial successfully. As a result, a test is intended to measure this
likelihood so that business decisions can be made based on its value.

In an A/B test there are two populations or branches, each of which is exposed to a different 
treatment. One branch is called the control, denoted in this article by A, which is usually a standard or baseline, 
and another is called the variant, denoted by B. The treatments could be different advertising campaigns, 
different form or content of a landing page on a website or different product offerings.

As discussed above, the populations have intrinsic success probabilities $\theta_a$ and $\theta_b$. 
The goal of this analysis is to provide a reccomendation about choosing A or B based on identitified 
business needs, using the data and justified by the statistics. 

Of course we have no idea what these intrinsic likelihoods are so we have to estimate them by exposing $n_a$ users
to our control branch A and expose $n_b$ users to our variant branch B and record how many of them actually
did what we wanted (bought a product, spent more than 10 min on a page, clicked the "register now" button, etc.)
we will represent this as $m_a$ and $m_b$ for each branch respectively. The fraction of people who did what we wanted
for each branch will be the following: 
\beq
\label{pa}
p_a = \frac{m_a}{n_a} and  p_b = \frac{m_b}{n_b}
\eeq

$p_a$ and $p_b$ are essentially our emperical estimates of the true likelihood of our success probabilities $\theta_a$ and $\theta_b$. 

In an AB Test, the implicit hypothesis is "B is better than A". However, this hypothesis is really
vaugue. What does "better" mean? Are we trying to look at the difference between probabilities? Are we looking at percent increases (lift)? There are an immesearable number of possible metrics and one needs to pick the right metric that uses these emperical estimates that can both be used in a way that not only aligns with business goals but also can be used in a way that makes sense in a hypothesis test. In this document we want to discuss various methodologies regaurding
hypothesis tests as well as outline three different metrics we have identified to fit the criteria discussed above. Ultimately, we want to use these metrics to compare and contrast these various schools of thought as a way to give you an idea about the different stories you can tell with your data.

\section{The Frequentist Approach\label{sec:freq}}

\subsection{A Primer on Hypothesis Testing}

Before we start getting into the different ways of evaluating ab test results from a frequentist perspective, I want to spend some time building 
towards a meta understanding of freqeuntist experiment design. When setting up our experiments we have 
some intuition about what evidence we expect to see if a particular hypothesis were to be 
true. For example, if a coin is heavily weighted to favor tails then you would expect to see 
a lot of tails showing up if you kept flipping that weighted coin. 
However, if we don’t know anything about the coin, how much evidence do we need to support 
the hypothesis that the coin is not fair (\(H1\)) as supposed to being fair (\(H0\))? 
One way could be to determine a variable \(S\) which is equal to the sum of \(n\) Bernoulli 
indicators (1 if Heads, 0 if tails). We know that the expected value of \(S\) when the coin is fair should be \(0.5n\).
As a result, we could look at the deviation of \(S\) from \(0.5n\): \(|S-0.5n|\) which we will call \(D\). 
Now it makes sense to say that if \(D\) was large enough then we can say start to see evidence of an unfair coin. 
In other words, we should pick a threshold $\epsilon$ such that if \(D\) $>$ $\epsilon$ then we have enough evidence to believe
that we have an unfair coin. But now youu are probably asking, how large does $\epsilon$ need to be for me
to be confident that I have enough evidence? Let's consider the tradeoffs if we pick $\epsilon$ arbitrarily. 
If we set $\epsilon$ equal to 2, then we would probably seem extremely paranoid because we were jumping to conclusions with little information. However, if we set $\epsilon$ to 100000 then we would probably be super gullible and
potentially lose a ton of money because we were exceedingly set in our ways. In other words, we want to think about our decision of $\epsilon$ in terms
of its tradeoff with our false alarm rate or Type 1 Error. This is tricky because in most cases, you will see
that a tradeoff since being less trigger happy means being more prone to inaction. As a result, we want to pick
a false alarm rate $\alpha$ and then calculate an $\epsilon$ such that the probability of seeing D$>$$\epsilon$ 
given that the null hypothesis is true is $\alpha$. Formally, this means we want to pick $\epsilon$ such that 
P( \(D\)$>$$\epsilon$ $|$ \(H0\)) = $\alpha$. What this means is that when we collect data and get a statistic D, 
if D is greater than your chosen epsilon then there is an $\alpha$ percent chance that your trial could have been 
a false alarm. In less theoretical terminology, if your $\alpha$ was 0.05 and you performed 1000 coin flips 100 times
5 of those experiments would yield results which would cause you to accuse your friend of cheating.

Now we want to concern ourselves with the problem of picking the right $\epsilon$ such that P(\(D\)$>$$\epsilon$ $|$ \(H0\)) = $\alpha$.
Since we are going to start doing some math, lets get rid of \(D\) and go back to our old notation which was \(|S-0.5n|\).
\beq
\label{eq:confidence_intervals}
P(|S-0.5n|>\epsilon | H0) = \alpha
\eeq
when the inequality is expressed in terms of S. 
\beq
\label{eq:confidence_intervals2}
P(\epsilon-0.5n < S <\epsilon+0.5n | H0) = 1-\alpha
\eeq
Now this is a bit confusing so we can use the fact that if p=0.5 then a binomial distribution is symetric for all n and k. 
Since we are evaluating this probability given that the null hypothesis is true, we can express the above as follows:
\beq
\label{eq:confidence_intervals3}
P(S < 0.5n-\epsilon | H0) = \alpha/2
\eeq
Finally, you can look at the cumulative distribution function (BCDF) of a binomial distribution and find 
the value X such that BCDF(X) = $\alpha$/2. As a result, your $\epsilon$ is 0.5n+X.

\subsection{Neyman Pearson Hypothesis Testing}

Hopefully the previous section gave you some intuition into the inner workings of a binary 
hypothesis test. Now I am going to introduce a meta framework for approaching hypothesis 
tests and then map our example to parts of this framework.\\

Before Data is Collected:

\begin{enumerate}
\item Define your null hypothesis (H0) and your alternative hypothesis (H1).
\begin{itemize}
	\item \textit{Our null hypothesis (H0) is "the coin is fair".}
	\item \textit{Our alternative hypothesis (H1) is "the coin is not fair".}
\end{itemize}
\item Choose a statistic S which summarizes the data to be obtained. This is a function H:$\Re^n$$\rightarrow$$\Re$) such that S = H($X_1$,$X_2$,....,$X_n$).
\begin{itemize}
	\item \textit{Our statistic S is the sum of bernoulli indicator variables.}
    \item \textit{S = $\sum\limits_{i=1}^n X_i$}
\end{itemize}
\item Determine the shape of the rejection region by specifying the set of S values for which H0 will be rejected as a function of $\epsilon$.
\begin{itemize}
	\item \textit{The shape of our rejection region is $|S-0.5n|>e$.}
\end{itemize}
\item Choose a false alarm rate $\alpha$.
\begin{itemize}
	\item \textit{Our false alarm rate is 0.05.}
\end{itemize}
\item Choose this critical value $\epsilon$ such that the probability S>$\epsilon$ is $\alpha$ given the fact that the null hypothesis is true.
\begin{itemize}
	\item \textit{As shown above. Using the BCDF, find a value X such that BCDF(X) = $\alpha$/2, then your epsilon is 0.5n+X. If we perform 1000 trials, then your epsilon is 31.}
\end{itemize}
\end{enumerate}

After Data is Collected

\begin{enumerate}
\item Calculate S.
\item Reject H0 if S is in rejection region
\end{enumerate}

So now that we have setup our experiment, let’s say we perform 1000 trials 
and we see 999 heads so D=499 which is way greater than 31. This means that we can reject the null hypothesis because D is way past our epsilon. 
This is the Neyman Pearson method of hypothesis testing which requires a lot of prior thought and the choosing of a false rejection rate 
before performing your experiment. A lot of modern statistics is used to the Fischer method of hypothesis testing which is to observe data 
and then figure out your false alarm rate and gauge whether it is good enough (IE, is my p-value less than 0.05?). 
This is subject to a lot of debate, but the main point of criticism of the Neyman Pearson method of hypothesis testing from the Fisher school 
is that the choice of a false rejection rate is an arbitrary one (IE there is no actionable difference between 0.05 and 0.06) which means you 
end up rejecting more hypotheses due to being unnecessarily cautious. As a result, the fisher exact tests and other methods have been 
popularized in modern statistics, especially in biological sciences which tend to have to test hypotheses with small sample sizes (n~=20). 
However, in the world of software where data literally grows on trees, too often do I see people p-hacking their tests and picking and choosing 
statistics as a way to justify their world view rather than believing that there is a good chance that their hypothesis is incorrect. 
In the next section, I am going to setup the AB Testing hypothesis testing problem and then walk you through the Neyman Pearson method 
of evaluating that test.

\subsection{Applying Neyman Pearson Hypothesis Testing to AB Testing}

In our hypothetical example, the buisness has been having a hard time with clients bouncing from a page
that drives customers to a lot of monetizing pages so we have been tasked with decreasing 
the number of bounces on that page. Let's say we come up with a variant that accordions away some of the copy
making the CTA's a lot more prevelant. Internally we believe that this new variant page (B) will inherently reduce the
bounce rate relative to our control page (A). For now, we will quantify "reduce" via a difference metric. In less abstract
terms, our hypothesis is that the true likelihood of a user not bouncing in our new variant ($\theta_B$)
is greater than that of the control ($\theta_A$). Formally, we have the following hypotheses:

\beq
    H_0 : \theta_A=\theta_B
\eeq
\beq
   H_A: \theta_B - \theta_A > 0
\eeq

The evidence we will be collecting is a series of bernoulli trials for each page. For each page, let's perform $n_A$
and $n_B$ trials on each variant and let $A_i$ and $B_i$ be the result of the i'th bernoulli trial where $A_i$ and $B_i$
is 1 if the user doesn't bounce and 0 if the user does. Keeping with the above framework, we now want to choose 
the statistics that both summarize our data and can be used to test the hypotheses we outlined above. Just like 
we discussed in the intro, the sum of these indicators will be summarized into $m_A$ and $m_B$. These variables are discussed below:

\beq
    m_A := Bin(n_A,\theta_A)
\eeq
\beq
   m_B := Bin(n_B,\theta_B)
\eeq

However, we want to use our data to estimate the true likelihood of boucing of users exposed to the control page ($\theta_A$) 
relative to the variant page ($\theta_B$). As a result, we need to normalize $m_A$ and $m_B$ by the total number of trials $n_A$
and $n_B$. This gives us $p_A$ and $p_B$ which we defined in the intro as the sample estimates of $\theta_A$ and $\theta_B$ 
respectively. Since we are looking at the difference metric, let's define our statistic S = $p_B$ - $p_A$. A general rule 
of thumb is to pick $\alpha$ = 0.05. Given this, we want to find some threshold $\epsilon$ such that if S > $\epsilon$ then
the difference is big enough for us to reject the null hypothesis with a 0.05 chance that we are wrong. As a result, we need to
evaluate the following for $\epsilon$: 

\beq
P( p_B - p_A > \epsilon | H_0 ) = 0.05
\eeq

If you evaluate the left side of the equation. You basically want to find the area under the PDF of S [ f(S) ]such that it's equal to 0.05. 
In other words, you want to evaluate the following for $\epsilon$. 

\beq
\int_{\epsilon}^{\infty} f(S) ds = 0.05
\eeq

Now the issue is that f(S) is a scaled binomial distribution. It's integral, unfortunately, has no real closed form solution so solving this equation for
$\epsilon$ can really only be done via monte carlo methods, or we can make simplifying assumptions about the pdf of S such that its integral can be evaluated.

Luckily, a popular result is that when $n > 100$, the binomial distribution converges towards the normal distribution and so does the scaled binomial distribution.
Given this assumption, we can use a well known fact that if S is a normally distributed variable, then S/$\sigma_S$ is a standard normal variable where $\sigma_S$ 
is the standard deviation of S. Now the question is what is $\sigma_S$ given that the null hypothesis is true (worth mentioning because this comes in handy later)? 
Let's do some math to derive a solid estimate. 

\beq
var(S | H_0) = var(p_A - p_B | H_0) = var(p_A | H_0) + var(p_B | H_0) 
\eeq
Now these variance equations are defined seperately as: 

\beq
var(p_A | H_0) = \frac{\theta_A(1-\theta_A)}{n_A}
\eeq

\beq
var(p_B | H_0) = \frac{\theta_B(1-\theta_B)}{n_B}
\eeq

Putting all this together we get:

\beq
var(S | H_0) = \frac{\theta_A(1-\theta_A)}{n_A} + \frac{\theta_B(1-\theta_B)}{n_B}
\eeq

Now we use the fact that if the null hypothesis is true, then $\theta_A$ = $\theta_B$. We will denote this common
value as $\theta$. As a result, our equation simplifies down to:

\beq
var(S | H_0) = \theta(1-\theta) [\frac{1}{n_A} + \frac{1}{n_B}]
\eeq

Now because we have no idea what $\theta$ truly is, we want to estimate it with the data we have. If the null hypothesis is
true, then all of our samples must come from the same distribution which means that our sample mean of this common distribution
($\hat{\theta}$) is:

\beq
\hat{\theta} = \frac{m_A + m_B}{n_A + n_B}
\eeq

Finally, we can derive our sample estimate for the standard deviation of S ($\hat{\sigma_S}$) is:

\beq
\hat{\sigma_S} = \hat{\theta}(1-\hat{\theta}) [\frac{1}{n_A} + \frac{1}{n_B}]
\eeq

Finally, we can define our statistic as a standard normally distributed variable for large sample sizes.
Now we can solve for $\epsilon$:

\beq
P ( \frac{p_B-p_A}{\hat{\sigma_S}} > \epsilon | H_0 ) = 0.05
\eeq

We can solve this by looking at the CDF of a standard normal distribution similar to what we did above for the coin example.

Once we have calculated our $\epsilon$, then we can start to collect evidence and if our sample statistic turns out to be greater
than our threshold $\epsilon$ then we can reject our null hypothesis and claim that there is sufficient evidence to believe that
our alternative hypothesis is true with a 5 percent risk of false alarm. Now that we understand how to evaluate ab testing results
with the difference metric and the Neyman Pearson style of hypothesis testing, we now want to answer what the ideal sample size is 
for our test. This will bring us into the next section where we stray from our false alarm rate and start thinking about statistical
power.

\subsection{Statistical Power and Choosing the ideal sample size} 







